{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Project_3 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr-Magnificent/minor-project/blob/master/Project_3_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "v7RI63_x5nFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import numpy as np\n",
        "import os, cv2\n",
        "from torchvision import models\n",
        "import torchvision.transforms as T\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aXOaNdIv5nFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j2yCHVhH5nFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jYktsHqC5nFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f88c99c5-2024-4822-9e5f-b9c804deb55b"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "03noI52R5nF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image_transform = T.Compose([T.Resize(256),\n",
        "                 T.CenterCrop(224),\n",
        "                 T.ToTensor(), \n",
        "                 T.Normalize(mean = [0.485, 0.456, 0.406], \n",
        "                             std = [0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "qU3IDfB05nGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_path(s):\n",
        "    paths = {\n",
        "        \"Images\" : \"data/images/\",\n",
        "        \"Vocab\" : \"data/kaggle/cleaned_mathml/vocab.csv\",\n",
        "        \"MathML\" : \"data/kaggle/cleaned_mathml/\"\n",
        "    }\n",
        "    return paths[s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aHJgWkQD5nGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image_file_names = os.listdir(get_path(\"Images\"))\n",
        "MathML_file_names = os.listdir(get_path(\"MathML\"))\n",
        "\n",
        "temp_image = []\n",
        "temp_mm = []\n",
        "\n",
        "for mm_name in set(MathML_file_names):\n",
        "    img_name = mm_name[:-4] + \".inkml.png\"\n",
        "    if(img_name in Image_file_names):\n",
        "        temp_image.append(img_name)\n",
        "        temp_mm.append(mm_name)\n",
        "        \n",
        "Image_file_names = temp_image\n",
        "MathML_file_names = temp_mm\n",
        "data_size = len(Image_file_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JYdZkv9b5nGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordtoint = {\n",
        "    '<SOS>' : 0\n",
        "}\n",
        "inttoword = {\n",
        "    0 : '<SOS>',\n",
        "}\n",
        "with open(get_path(\"Vocab\")) as f:\n",
        "    words = f.read().strip().split(\" \")\n",
        "    for e, word in enumerate(words):\n",
        "        wordtoint[word] = e+1\n",
        "        inttoword[e+1] = word\n",
        "end = len(wordtoint)\n",
        "wordtoint['<EOS>'] = end\n",
        "inttoword[end] = '<EOS>'\n",
        "SOS_token = 0\n",
        "EOS_token = end"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rFEYV9TH5nG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_pair(index):\n",
        "    img = Image.fromarray(cv2.imread(get_path(\"Images\") + Image_file_names[index]))\n",
        "    img = Image_transform(img).unsqueeze(0)\n",
        "    tar = None\n",
        "    with open(get_path(\"MathML\") + MathML_file_names[index]) as f:\n",
        "        arr = f.read().strip().split(\" \")\n",
        "        tar = [torch.tensor([wordtoint[word]]) for word in arr]\n",
        "    tar.append(torch.tensor([EOS_token]))\n",
        "    tar = torch.tensor(tar).reshape(-1, 1)\n",
        "    return img, tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JmjheCtq5nHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        temp_model = models.densenet169(pretrained=True)\n",
        "        modules = list(temp_model.children())[:-1]\n",
        "        self.densenet = nn.Sequential(*modules)\n",
        "        for p in self.densenet.parameters():\n",
        "            p.requires_grad = False\n",
        "        \n",
        "        self.cnn1 = nn.Conv2d(1664, 1500, kernel_size=(1,1))\n",
        "        self.cnn2 = nn.Conv2d(1500, 1400, kernel_size=(1,1))\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, image):\n",
        "        output = self.densenet(image)\n",
        "        output = self.relu(self.cnn2(self.relu(self.cnn1(output))))\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bm6y2i4f5nHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, drop_prob=0.1, max_size=MAX_LENGTH):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.drop_prob = drop_prob\n",
        "        self.max_size = max_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attn = nn.Linear(hidden_size * 2, max_size)\n",
        "        self.attn_combine = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, inp, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(inp).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "#         print(attn_weights.shape)\n",
        "#         print(encoder_outputs.shape)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "        \n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        \n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cUAub59j5nHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bHw992zn5nHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    target_length = target_tensor.size(0)\n",
        "#     print(input_tensor.shape)\n",
        "#     print(target_tensor.shape)\n",
        "#     encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    encoder_outputs = encoder(input_tensor).reshape(200, -1)\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "#     print(encoder_outputs.shape)\n",
        "    \n",
        "    decoder_hidden = decoder.initHidden()\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # print(target_tensor[di], decoder_output)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            \n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lUUZeuSE5nHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=5, learning_rate=0.001):\n",
        "    start = time.time()\n",
        "    encoder = encoder.to(device)\n",
        "    decoder = decoder.to(device)\n",
        "    encoder_optimizer = optim.Adam([\n",
        "                                    {\"params\" : encoder.cnn1.parameters()},\n",
        "                                    {\"params\" : encoder.cnn2.parameters()}\n",
        "                                ], lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    plot_losses = []\n",
        "    \n",
        "    for i in range(1, n_iters + 1):\n",
        "        data_index = list(range(data_size))\n",
        "        random.shuffle(data_index)\n",
        "        print_loss_total = 0\n",
        "        plot_loss_total = 0\n",
        "        for k in range(1, 1001):\n",
        "            input_tensor, target_tensor = get_input_pair(data_index[k])\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target_tensor = target_tensor.to(device)\n",
        "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "#             if((k+1)%1000 == 0):\n",
        "#                 print(f'Loss at sample-> {k} = {loss}')\n",
        "            print_loss_total += loss\n",
        "            plot_loss_total += loss\n",
        "\n",
        "        if i % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / n_iters), i, i / n_iters * 100, print_loss_avg))\n",
        "        \n",
        "        plot_loss_avg = plot_loss_total / 1000\n",
        "        plot_losses.append(plot_loss_avg)\n",
        "        if(i %10 == 0):\n",
        "            save_state(i, encoder, encoder_optimizer, decoder, decoder_optimizer)\n",
        "#     showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h0uAJbJ75nH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z-Vu2oxD5nIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_state(epoch, encoder, encoder_optimizer, decoder, decoder_optimizer):\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'encoder_state_dict': encoder.state_dict(),\n",
        "            'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
        "            'decoder_state_dict': decoder.state_dict(),\n",
        "            'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
        "            }, \"checkpoint\" + str(epoch) + \".pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yqHclr735nIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hidden_size = 256\n",
        "# encoder1 = Encoder().to(device)\n",
        "# attn_decoder1 = AttnDecoder(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "luJ6BRIt5nIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "6d721195-b36f-4531-ce47-3153c01e8df0"
      },
      "source": [
        "encoder = Encoder()\n",
        "decoder = Decoder(343, len(wordtoint))\n",
        "trainIters(encoder, decoder, 50, 5)\n",
        "# model_states = torch.load('../input/modeltest/checkpoint10.pth', map_location=device)\n",
        "# encoder.load_state_dict(model_states[\"encoder_state_dict\"])\n",
        "# decoder.load_state_dict(model_states[\"decoder_state_dict\"])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14m 23s (- 129m 30s) (5 10%) 455.9240\n",
            "28m 52s (- 115m 31s) (10 20%) 440.5972\n",
            "43m 27s (- 101m 23s) (15 30%) 438.6919\n",
            "57m 48s (- 86m 43s) (20 40%) 428.2640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-eb2b08462b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m343\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordtoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# model_states = torch.load('../input/modeltest/checkpoint10.pth', map_location=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# encoder.load_state_dict(model_states[\"encoder_state_dict\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-951a3e68bbf7>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, learning_rate)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#             if((k+1)%1000 == 0):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#                 print(f'Loss at sample-> {k} = {loss}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-d72e8e49a119>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Without teacher forcing: use its own predictions as the next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# detach from history as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-ad064ee41711>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q32sz5jN5nIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainIters(encoder, decoder, 1000, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BNi7cIky5nIb",
        "colab_type": "code",
        "colab": {},
        "outputId": "16c2c2f5-cb94-45ea-8149-6171d3cb3957"
      },
      "source": [
        "img, tar = get_input_pair(0)\n",
        "out = encoder(img).reshape(200, -1)\n",
        "hid = decoder.initHidden()\n",
        "start = torch.tensor([SOS_token])\n",
        "with open(get_path(\"MathML\") + MathML_file_names[0]) as f:\n",
        "    arr = f.read().strip().split(\" \")\n",
        "for i in range(len(arr)):\n",
        "    ans, hid, attn = decoder(start, hid, out)\n",
        "    print(inttoword[int(F.softmax(ans).argmax())],arr[i])\n",
        "    start = F.softmax(ans).argmax()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<mrow> <mrow>\n",
            "<mi> <mi>\n",
            "s s\n",
            "</mi> </mi>\n",
            "<mrow> <mrow>\n",
            "<mo> <mo>\n",
            "( (\n",
            "</mo> </mo>\n",
            "<mrow> <mrow>\n",
            "<mi> <mi>\n",
            "u u\n",
            "</mi> </mi>\n",
            "<mrow> <mrow>\n",
            "<mo> <mo>\n",
            ") )\n",
            "</mo> </mo>\n",
            "<mrow> <mrow>\n",
            "<mo> <mo>\n",
            ") =\n",
            "</mo> </mo>\n",
            "<mrow> <mfrac>\n",
            "<mo> <mrow>\n",
            ") <mi>\n",
            "</mo> sin\n",
            "<mrow> </mi>\n",
            "<mo> <mrow>\n",
            ") <mo>\n",
            "</mo> (\n",
            "<mrow> </mo>\n",
            "<mo> <mrow>\n",
            ") <mi>\n",
            "</mo> u\n",
            "<mrow> </mi>\n",
            "<mo> <mo>\n",
            ") )\n",
            "</mo> </mo>\n",
            "<mrow> </mrow>\n",
            "<mo> </mrow>\n",
            ") </mrow>\n",
            "</mo> <mrow>\n",
            "<mrow> <mi>\n",
            "<mo> sin\n",
            ") </mi>\n",
            "</mo> <mrow>\n",
            "<mrow> <mo>\n",
            "<mo> (\n",
            ") </mo>\n",
            "</mo> <mrow>\n",
            "<mrow> <mi>\n",
            "<mo> lambda\n",
            ") </mi>\n",
            "</mo> <mo>\n",
            "<mrow> )\n",
            "<mo> </mo>\n",
            ") </mrow>\n",
            "</mo> </mrow>\n",
            "<mrow> </mrow>\n",
            "<mo> </mfrac>\n",
            ") </mrow>\n",
            "</mo> </mrow>\n",
            "<mrow> </mrow>\n",
            "<mo> </mrow>\n",
            ") </mrow>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n",
            "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u0gNl39-5nIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "['<mrow>',\n",
        " '<mi>',\n",
        " 's',\n",
        " '</mi>',\n",
        " '<mrow>',\n",
        " '<mo>',\n",
        " '(',\n",
        " '</mo>',\n",
        " '<mrow>',\n",
        " '<mi>',\n",
        " 'u',\n",
        " '</mi>',\n",
        " '<mrow>',\n",
        " '<mo>',\n",
        " ')',\n",
        " '</mo>',\n",
        " '<mrow>',\n",
        " '<mo>',\n",
        " '=',\n",
        " '</mo>',\n",
        " '<mfrac>',\n",
        " '<mrow>',\n",
        " '<mi>',\n",
        " 'sin',\n",
        " '</mi>',\n",
        " '<mrow>',\n",
        " '<mo>',\n",
        " '(',\n",
        " '</mo>',\n",
        " '<mrow>',\n",
        " '<mi>',\n",
        " 'u',\n",
        " '</mi>',\n",
        " '<mo>',\n",
        " ')',\n",
        " '</mo>',\n",
        " '</mrow>',\n",
        " '</mrow>',\n",
        " '</mrow>',\n",
        " '<mrow>',\n",
        " '<mi>',\n",
        " 'sin',\n",
        " '</mi>',\n",
        " '<mrow>',\n",
        " '<mo>',\n",
        " '(',\n",
        " '</mo>',\n",
        " '<mrow>',\n",
        " '<mi>',\n",
        " 'lambda',\n",
        " '</mi>',\n",
        " '<mo>',\n",
        " ')',\n",
        " '</mo>',\n",
        " '</mrow>',\n",
        " '</mrow>',\n",
        " '</mrow>',\n",
        " '</mfrac>',\n",
        " '</mrow>',\n",
        " '</mrow>',\n",
        " '</mrow>',\n",
        " '</mrow>',\n",
        " '</mrow>']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n08NlsYN5nIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder_hidden = decoder.initHidden()\n",
        "# inp_tar = torch.tensor([0])\n",
        "# for i in range(len(exp_tar)+1):\n",
        "#     decoder_output, decoder_hidden, decoder_attention = decoder(inp_tar, decoder_hidden, out)\n",
        "#     if(i == len(exp_tar)):\n",
        "#         break\n",
        "#     inp_tar = exp_tar[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WcYMMbYx5nI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ans = 0\n",
        "# for i in range(data_size):\n",
        "#     img, tar = get_input_pair(i)\n",
        "#     ans = max(ans, len(tar))\n",
        "# ans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9c5PW9q05nI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(wordtoint)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vtZ_yw5E5nJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}